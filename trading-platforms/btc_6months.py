#!/usr/bin/env python3
"""
PRACTICAL APPROACH: Get 6 months of recent BTCUSDT data
Perfect for backtesting, guaranteed to work
"""

import pandas as pd
import requests
import time
from datetime import datetime
import os

def get_btcusdt_6_months():
    """Get 6 months of recent BTCUSDT hourly data"""
    
    print("ðŸŽ¯ PRACTICAL APPROACH: Getting 6 months of BTCUSDT data")
    print("=" * 60)
    print("ðŸ“Š 6 months Ã— 30 days Ã— 24 hours = ~4,320 hours")
    print("ðŸ“¦ At 1000 per batch = ~5 batches = ~1 second total")
    
    all_data = []
    target_hours = 6 * 30 * 24  # 6 months worth
    batches_needed = (target_hours // 1000) + 1
    
    print(f"ðŸŽ¯ Target: {target_hours} hours in {batches_needed} batches")
    
    current_end_time = None
    batch_count = 0
    
    start_time = time.time()
    
    while len(all_data) < target_hours and batch_count < 10:  # Safety limit
        batch_count += 1
        
        params = {
            'symbol': 'BTCUSDT', 
            'interval': '1h',
            'limit': 1000
        }
        
        if current_end_time:
            params['endTime'] = current_end_time
        
        print(f"ðŸ“¡ Batch {batch_count}/~{batches_needed}...", end=" ")
        
        try:
            response = requests.get("https://api.binance.com/api/v3/klines", params=params, timeout=30)
            
            if response.status_code != 200:
                print(f"âŒ Status: {response.status_code}")
                break
                
            data = response.json()
            
            if not data:
                print("âœ… Done!")
                break
                
            all_data.extend(data)
            print(f"âœ… +{len(data)} | Total: {len(all_data):,}")
            
            # Set up for next batch
            first_time = data[0][0]  # First record's open time
            current_end_time = first_time - 1
            
            time.sleep(0.1)  # Be nice to API
            
        except Exception as e:
            print(f"âŒ Error: {e}")
            break
    
    elapsed = time.time() - start_time
    print(f"\nâ° Completed in {elapsed:.1f} seconds")
    print(f"ðŸ“Š Collected {len(all_data):,} records")
    
    # Convert to DataFrame
    print("ðŸ“ Converting to DataFrame...")
    
    columns = [
        'open_time', 'open', 'high', 'low', 'close', 'volume',
        'close_time', 'quote_asset_volume', 'number_of_trades',
        'taker_buy_base_asset_volume', 'taker_buy_quote_asset_volume', 'ignore'
    ]
    
    df = pd.DataFrame(all_data, columns=columns)
    
    # Convert timestamps
    df['open_time'] = pd.to_datetime(df['open_time'], unit='ms')
    df['close_time'] = pd.to_datetime(df['close_time'], unit='ms')
    
    # Convert prices
    for col in ['open', 'high', 'low', 'close', 'volume']:
        df[col] = pd.to_numeric(df[col])
    
    # Sort chronologically  
    df = df.sort_values('open_time').reset_index(drop=True)
    
    # Save to CSV
    output_file = "btcusdt_6months.csv"
    print(f"ðŸ’¾ Saving to {output_file}...")
    df.to_csv(output_file, index=False)
    
    file_size = os.path.getsize(output_file) / (1024 * 1024)
    days = (df['open_time'].max() - df['open_time'].min()).days
    
    print(f"\nâœ… SUCCESS!")
    print(f"ðŸ“ File: {output_file} ({file_size:.1f} MB)")
    print(f"ðŸ“Š Records: {len(df):,} hours")
    print(f"ðŸ“… From: {df['open_time'].min()}")
    print(f"ðŸ“… To: {df['open_time'].max()}")
    print(f"ðŸ“ˆ Days: {days}")
    print(f"ðŸ’° Price: ${df['low'].min():,.0f} - ${df['high'].max():,.0f}")
    print(f"ðŸ’° Latest: ${df['close'].iloc[-1]:,.0f}")
    
    print(f"\nðŸŽ¯ 6 MONTHS OF DATA READY FOR BACKTESTING! ðŸš€")
    
    return df

if __name__ == "__main__":
    get_btcusdt_6_months()